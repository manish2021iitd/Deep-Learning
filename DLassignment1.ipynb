{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQoon58TL4bE8E6HNyPU1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish2021iitd/Deep-Learning/blob/main/DLassignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion-MNIST dataset\n",
        "(training_images, training_labels), (testing_images,testing_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Plot one sample image for each class\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(training_images[training_labels == i][0], cmap='gray')\n",
        "    plt.title(class_names[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "peru7mjbMqTV",
        "outputId": "08187340-b215-42ad-f545-3105d227477b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        self.input_size = input_size #number of inputs nodes\n",
        "        self.hidden_sizes = hidden_sizes #list of neurons in each hidden layer\n",
        "        self.output_size = output_size #number of output neurons in output layer\n",
        "        self.weights = [] #list of weight matrices for each layer\n",
        "        self.biases = []  #list of bias vectors for each hidden layer and output layer\n",
        "\n",
        "        #innitializing the weights and biases for each layer\n",
        "        sizes = [input_size] + hidden_sizes + [output_size] #using list concatination to make a list of number of nodes in each layer\n",
        "        for i in range(len(sizes) - 1):\n",
        "            self.weights.append(np.random.randn(sizes[i+1], sizes[i]))\n",
        "            self.biases.append(np.random.randn(sizes[i+1]))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "      # Forward pass\n",
        "      activations = [X]\n",
        "      for i in range(len(self.weights)):\n",
        "        z = np.dot(activations[-1], self.weights[i].T) + self.biases[i]  # Transpose weight matrix\n",
        "        a = self.sigmoid(z) if i < len(self.weights) - 1 else self.softmax(z)\n",
        "        activations.append(a)\n",
        "      return activations\n",
        "\n",
        "    def predict(self, X):\n",
        "        #predict output probabilities\n",
        "        activations = self.forward(X)\n",
        "        return activations[-1]\n",
        "\n",
        "#load fashion-mnist dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "#define neural network\n",
        "input_size = X_train.shape[1]  #28x28 images flattened\n",
        "hidden_sizes = [128, 64]  #size of hidden layers\n",
        "output_size = 10  # 10 classes in fashion-mnist\n",
        "\n",
        "#initialize neural network\n",
        "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
        "\n",
        "#predict probabilities for the test set\n",
        "probabilities = model.predict(X_test)\n",
        "\n",
        "#print the output probabilities\n",
        "print(\"Output Probabilities:\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaWViZYXMzya",
        "outputId": "0eb8ae20-2fd3-4bb4-d43d-ad87336d0d2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Probabilities: [[9.01490897e-03 3.29127908e-03 4.10224864e-02 ... 2.48694513e-01\n",
            "  3.21784631e-02 7.32184604e-04]\n",
            " [3.39104918e-01 1.32987067e-03 1.41483443e-04 ... 1.04984767e-03\n",
            "  1.36490678e-04 3.27866023e-03]\n",
            " [7.79620447e-05 2.05533719e-03 5.26934570e-04 ... 2.95792288e-05\n",
            "  1.18830973e-04 3.16500202e-05]\n",
            " ...\n",
            " [1.51491871e-03 1.09465295e-02 1.02829645e-02 ... 6.56370874e-03\n",
            "  6.22244228e-02 1.51639659e-05]\n",
            " [2.03394459e-05 1.16446999e-03 6.98837973e-03 ... 1.89181325e-05\n",
            "  1.04977374e-04 3.29145420e-05]\n",
            " [1.45428690e-03 2.19035859e-03 4.51465040e-01 ... 5.29991994e-03\n",
            "  7.93807848e-05 1.69068504e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "        self.output_size = output_size\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        #initialize weights and biases for each layer\n",
        "        sizes = [input_size] + hidden_sizes + [output_size]\n",
        "        for i in range(len(sizes) - 1):\n",
        "            self.weights.append(np.random.randn(sizes[i+1], sizes[i]))\n",
        "            self.biases.append(np.random.randn(sizes[i+1],1))\n",
        "\n",
        "        #initialize velocities for momentum-based optimization\n",
        "        self.velocities = [np.zeros_like(w) for w in self.weights]\n",
        "\n",
        "        #initialize rmsprop parameters\n",
        "        self.rmsprop_cache_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.rmsprop_cache_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "        #initialize adam parameters\n",
        "        self.adam_m_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.adam_m_b = [np.zeros_like(b) for b in self.biases]\n",
        "        self.adam_v_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.adam_v_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def d_sigmoid(self,x):\n",
        "      return self.sigmoid(x)*(1-self.sigmoid(x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "      exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "      return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    def logloss(self, y, y_label):\n",
        "      error = -(y_label*np.log(y+1e-10)+(1-y_label)*np.log(1-y+1e-10))\n",
        "      return np.sum(error, axis = 0)/error.shape[0]\n",
        "\n",
        "    def Cross_entropy(self, y, y_hat):\n",
        "      da = (1-y)/(1-y_hat) - (y)/(y_hat+1e-10)\n",
        "      epoch_loss = self.__logloss(y_hat, y)\n",
        "      return da, epoch_loss\n",
        "\n",
        "    #forwardpropagation\n",
        "    def forward(self, X):\n",
        "      activations = [X] #create a list of all activations\n",
        "      for i in range(len(self.weights)):\n",
        "        z = np.dot(self.weights[i],activations[-1].T) + self.biases[i]  #preactivation\n",
        "        a = self.sigmoid(z) if i < len(self.weights) - 1 else self.softmax(z) #activation/output\n",
        "        activations.append(a) #appending the activations list\n",
        "      return activations\n",
        "\n",
        "    #backwardpropagation\n",
        "    def backward(self, y, activations):\n",
        "        delta = activations[-1] - y\n",
        "        for i in range(len(self.weights) - 1, -1, -1):\n",
        "            dz = delta * (activations[i+1] * (1 - activations[i+1])) if i < len(self.weights) - 1 else delta\n",
        "            dw = np.dot(dz.T, activations[i])\n",
        "            db = np.sum(dz, axis=0)\n",
        "            delta = np.dot(dz, self.weights[i])\n",
        "        return dw,db\n",
        "\n",
        "\n",
        "    def update(self, X, y, optimizer, epochs, learning_rate=0.0001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "      for _ in range(epochs):\n",
        "        activations = self.forward(X)\n",
        "        dw, db = self.backward(y, activations)\n",
        "\n",
        "        if optimizer == 'sgd':\n",
        "          for i in range(len(self.weights)):\n",
        "            self.weights[i] -= learning_rate * dw[i]\n",
        "            self.biases[i] -= learning_rate * db[i]\n",
        "\n",
        "        elif optimizer == 'momentum':\n",
        "          for i in range(len(self.weights)):\n",
        "            self.velocities[i] = beta1 * self.velocities[i] + (1 - beta1) * dw[i]\n",
        "            self.weights[i] -= learning_rate * self.velocities[i]\n",
        "            self.biases[i] -= learning_rate * db[i]\n",
        "\n",
        "        elif optimizer == 'nesterov':\n",
        "          lookahead_weights = [w - beta1 * v for w, v in zip(self.weights, self.velocities)]\n",
        "          lookahead_biases = [b - beta1 * v[-1] for b, v in zip(self.biases, self.velocities)]\n",
        "          lookahead_activations = self.forward(X)\n",
        "          lookahead_dw, lookahead_db = self.backward(y, lookahead_activations)\n",
        "          for i in range(len(self.weights)):\n",
        "            self.velocities[i] = beta1 * self.velocities[i] + (1 - beta1) * lookahead_dw[i]\n",
        "            self.weights[i] -= learning_rate * self.velocities[i]\n",
        "            self.biases[i] -= learning_rate * lookahead_db[i]\n",
        "\n",
        "        elif optimizer == 'rmsprop':\n",
        "          for i in range(len(self.weights)):\n",
        "            self.rmsprop_cache_w[i] = beta1 * self.rmsprop_cache_w[i] + (1 - beta1) * dw[i]**2\n",
        "            self.rmsprop_cache_b[i] = beta1 * self.rmsprop_cache_b[i] + (1 - beta1) * db[i]**2\n",
        "            self.weights[i] -= learning_rate * dw[i] / (np.sqrt(self.rmsprop_cache_w[i]) + epsilon)\n",
        "            self.biases[i] -= learning_rate * db[i] / (np.sqrt(self.rmsprop_cache_b[i]) + epsilon)\n",
        "\n",
        "        elif optimizer == 'adam':\n",
        "          for i in range(len(self.weights)):\n",
        "            self.adam_m_w[i] = beta1 * self.adam_m_w[i] + (1 - beta1) * dw[i]\n",
        "            self.adam_m_b[i] = beta1 * self.adam_m_b[i] + (1 - beta1) * db[i]\n",
        "            self.adam_v_w[i] = beta2 * self.adam_v_w[i] + (1 - beta2) * dw[i]**2\n",
        "            self.adam_v_b[i] = beta2 * self.adam_v_b[i] + (1 - beta2) * db[i]**2\n",
        "            m_w_hat = self.adam_m_w[i] / (1 - beta1**(i+1))\n",
        "            m_b_hat = self.adam_m_b[i] / (1 - beta1**(i+1))\n",
        "            v_w_hat = self.adam_v_w[i] / (1 - beta2**(i+1))\n",
        "            v_b_hat = self.adam_v_b[i] / (1 - beta2**(i+1))\n",
        "            self.weights[i] -= learning_rate * m_w_hat / (np.sqrt(v_w_hat) + epsilon)\n",
        "            self.biases[i] -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n",
        "\n",
        "        elif optimizer == 'nadam':\n",
        "          for i in range(len(self.weights)):\n",
        "            self.adam_m_w[i] = beta1 * self.adam_m_w[i] + (1 - beta1) * dw[i]\n",
        "            self.adam_m_b[i] = beta1 * self.adam_m_b[i] + (1 - beta1) * db[i]\n",
        "            self.adam_v_w[i] = beta2 * self.adam_v_w[i] + (1 - beta2) * dw[i]**2\n",
        "            self.adam_v_b[i] = beta2 * self.adam_v_b[i] + (1 - beta2) * db[i]**2\n",
        "            m_w_hat = self.adam_m_w[i] / (1 - beta1**(i+1))\n",
        "            m_b_hat = self.adam_m_b[i] / (1 - beta1**(i+1))\n",
        "            v_w_hat = self.adam_v_w[i] / (1 - beta2**(i+1))\n",
        "            v_b_hat = self.adam_v_b[i] / (1 - beta2**(i+1))\n",
        "            self.weights[i] -= learning_rate * m_w_hat / (np.sqrt(v_w_hat) + epsilon)\n",
        "            self.biases[i] -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n",
        "\n",
        "\n",
        "    def train(self, X, y, optimizer, epochs, batch_size):\n",
        "      #train the neural network using different optimizers\n",
        "      for epoch in range(epochs):\n",
        "        for i in range(0, len(X), batch_size):\n",
        "          X_batch = X[i:i+batch_size]\n",
        "          y_batch = y[i:i+batch_size]\n",
        "          self.update(X_batch,y_batch,optimizer,epochs)\n",
        "\n",
        "    def test(self, X):\n",
        "      activations = self.forward(X)\n",
        "      return activations[-1]\n",
        "\n",
        "\n",
        "#load fashion-mnist dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train.shape)\n",
        "#define neural network\n",
        "input_size = 784#size of inputs\n",
        "hidden_sizes = [128, 64]  #size of neurons in each hidden layers\n",
        "output_size = 10  #taking 10 output neurons as we have classify 10 classes in fashion-mnist\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_one_hot = np.eye(num_classes)[y_train]\n",
        "y_test_one_hot = np.eye(num_classes)[y_test]\n",
        "\n",
        "#initialize neural network\n",
        "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
        "\n",
        "#please choose optimizer = 'sgd'/'momentum'/'nesterov'/'rmsprop'/'adam'/'nadam'\n",
        "#and number of epochs and batch size here\n",
        "model.train(X_train, y_train_one_hot,'nadam', epochs=10, batch_size=32)\n",
        "\n",
        "results = model.test(X_test)\n",
        "\n",
        "results = np.argmax(results, axis=-1)\n",
        "real_labels = np.argmax(y_test, axis=-1)\n",
        "accuracy = sum(1*(results==real_labels))/len(results)\n",
        "print(\"The accuracy of testing is \", accuracy*100, \"%\")\n",
        "#References:\n",
        "#1.https://cs229.stanford.edu/main_notes.pdf\n",
        "#2.http://www.cse.iitm.ac.in/~miteshk/CS6910.html\n",
        "#3.https://visualstudiomagazine.com/Articles/2017/06/01/Back-Propagation.aspx?Page=2\n",
        "#4.https://medium.com/@ipylypenko/exploring-neural-networks-with-fashion-mnist-b0a8214b7b7b\n",
        "#5.https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3\n",
        "#7.https://www.youtube.com/watch?v=LQvRhQwDOm0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Nm7URO24NPHS",
        "outputId": "66a48d3c-cd5b-498b-ed1d-564a446eb2d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (64,128) and (32,128) not aligned: 128 (dim 1) != 32 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-dd381d04b80b>\u001b[0m in \u001b[0;36m<cell line: 167>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;31m#please choose optimizer = 'sgd'/'momentum'/'nesterov'/'rmsprop'/'adam'/'nadam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;31m#and number of epochs and batch size here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nadam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-dd381d04b80b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, optimizer, epochs, batch_size)\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m           \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-dd381d04b80b>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, X, y, optimizer, epochs, learning_rate, beta1, beta2, epsilon)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-dd381d04b80b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#create a list of all activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#preactivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#activation/output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#appending the activations list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (64,128) and (32,128) not aligned: 128 (dim 1) != 32 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "        self.output_size = output_size\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        # Initialize weights and biases for each layer\n",
        "        sizes = [input_size] + hidden_sizes + [output_size]\n",
        "        for i in range(len(sizes) - 1):\n",
        "            self.weights.append(np.random.randn(sizes[i+1], sizes[i]))\n",
        "            self.biases.append(np.random.randn(sizes[i+1]))\n",
        "\n",
        "        # Initialize velocities for momentum-based optimization\n",
        "        self.velocities = [np.zeros_like(w) for w in self.weights]\n",
        "\n",
        "        # Initialize rmsprop parameters\n",
        "        self.rmsprop_cache_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.rmsprop_cache_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "        # Initialize adam parameters\n",
        "        self.adam_m_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.adam_m_b = [np.zeros_like(b) for b in self.biases]\n",
        "        self.adam_v_w = [np.zeros_like(w) for w in self.weights]\n",
        "        self.adam_v_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def d_sigmoid(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    def logloss(self, y, y_label):\n",
        "        error = -(y_label * np.log(y + 1e-10) + (1 - y_label) * np.log(1 - y + 1e-10))\n",
        "        return np.sum(error, axis=0) / error.shape[0]\n",
        "\n",
        "    def Cross_entropy(self, y, y_hat):\n",
        "        da = (1 - y) / (1 - y_hat) - (y) / (y_hat + 1e-10)\n",
        "        epoch_loss = self.logloss(y_hat, y)\n",
        "        return da, epoch_loss\n",
        "\n",
        "    # Forward propagation\n",
        "    def forward(self, X):\n",
        "        activations = [X] # Create a list of all activations\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activations[-1], self.weights[i].T) + self.biases[i]  # Preactivation\n",
        "            a = self.sigmoid(z) if i < len(self.weights) - 1 else self.softmax(z) # Activation/output\n",
        "            activations.append(a) # Append the activations list\n",
        "        return activations\n",
        "\n",
        "    # Backward propagation\n",
        "    def backward(self, y, activations):\n",
        "        delta = activations[-1] - y\n",
        "        for i in range(len(self.weights) - 1, -1, -1):\n",
        "            dz = delta * (activations[i+1] * (1 - activations[i+1])) if i < len(self.weights) - 1 else delta\n",
        "            dw = np.dot(dz.T, activations[i])\n",
        "            db = np.sum(dz, axis=0)\n",
        "            delta = np.dot(dz, self.weights[i])\n",
        "        return dw, db\n",
        "\n",
        "    def optimizer(self, X, y, optimizer, epochs, learning_rate=0.0001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        for _ in range(epochs):\n",
        "            activations = self.forward(X)\n",
        "            dw, db = self.backward(y, activations)\n",
        "\n",
        "            if optimizer == 'sgd':\n",
        "                self.weights -= learning_rate * dw\n",
        "                self.biases -= learning_rate * db\n",
        "            elif optimizer == 'momentum':\n",
        "                self.velocities = beta1 * np.array(self.velocities) + (1 - beta1) * dw\n",
        "                self.weights -= learning_rate * np.array(self.velocities)\n",
        "                self.biases -= learning_rate * db\n",
        "            elif optimizer == 'rmsprop':\n",
        "                self.rmsprop_cache_w = beta1 * np.array(self.rmsprop_cache_w) + (1 - beta1) * dw**2\n",
        "                self.rmsprop_cache_b = beta1 * np.array(self.rmsprop_cache_b) + (1 - beta1) * db**2\n",
        "                self.weights -= learning_rate * dw / (np.sqrt(self.rmsprop_cache_w) + epsilon)\n",
        "                self.biases -= learning_rate * db / (np.sqrt(self.rmsprop_cache_b) + epsilon)\n",
        "            elif optimizer == 'adam':\n",
        "                self.adam_m_w = beta1 * np.array(self.adam_m_w) + (1 - beta1) * dw\n",
        "                self.adam_m_b = beta1 * np.array(self.adam_m_b) + (1 - beta1) * db\n",
        "                self.adam_v_w = beta2 * np.array(self.adam_v_w) + (1 - beta2) * dw**2\n",
        "                self.adam_v_b = beta2 * np.array(self.adam_v_b) + (1 - beta2) * db**2\n",
        "                m_w_hat = self.adam_m_w / (1 - beta1**(i+1))\n",
        "                m_b_hat = self.adam_m_b / (1 - beta1**(i+1))\n",
        "                v_w_hat = self.adam_v_w / (1 - beta2**(i+1))\n",
        "                v_b_hat = self.adam_v_b / (1 - beta2**(i+1))\n",
        "                self.weights -= learning_rate * m_w_hat / (np.sqrt(v_w_hat) + epsilon)\n",
        "                self.biases -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n",
        "\n",
        "    def train(self, X, y, optimizer, epochs, batch_size):\n",
        "        # Train the neural network using different optimizers\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(0, len(X), batch_size):\n",
        "                X_batch = X[i:i+batch_size]\n",
        "                y_batch = y[i:i+batch_size]\n",
        "                self.optimizer(X_batch, y_batch, optimizer, epochs)\n",
        "\n",
        "    def test(self, X):\n",
        "        activations = self.forward(X)\n",
        "        return activations[-1]\n",
        "\n",
        "# Load fashion-mnist dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_one_hot = np.eye(num_classes)[y_train]\n",
        "y_test_one_hot = np.eye(num_classes)[y_test]\n",
        "\n",
        "# Initialize neural network\n",
        "input_size = X_train.shape[1]  # Size of inputs\n",
        "hidden_sizes = [128, 64]  # Size of neurons in each hidden layer\n",
        "output_size = 10  # Taking 10 output neurons as we have to classify 10 classes in fashion-mnist\n",
        "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
        "\n",
        "# Choose optimizer and other parameters\n",
        "optimizer = 'sgd'  # You can choose 'momentum', 'rmsprop', 'adam', etc.\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Train the model\n",
        "model.train(X_train, y_train_one_hot, optimizer, epochs, batch_size)\n",
        "\n",
        "# Test the model\n",
        "results = model.test(X_test)\n",
        "\n",
        "results = np.argmax(results, axis=-1)\n",
        "real_labels = np.argmax(y_test_one_hot, axis=-1)\n",
        "accuracy = sum(1*(results==real_labels))/len(results)\n",
        "print(\"The accuracy of testing is \", accuracy*100, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "u8u2-QTVN6ys",
        "outputId": "67e1de49-9a10-4458-d88c-4116178bb779"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d3dabec771ca>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# Test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d3dabec771ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, optimizer, epochs, batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d3dabec771ca>\u001b[0m in \u001b[0;36moptimizer\u001b[0;34m(self, X, y, optimizer, epochs, learning_rate, beta1, beta2, epsilon)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
          ]
        }
      ]
    }
  ]
}