{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB0ccJiF4Mk+tNrLoExJGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7df4730d95641b3aa612793753d11c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06fa748a71294571b9aa3b8f974b2792",
              "IPY_MODEL_e04a6c17fcb5465783bd6682ad11fd7d"
            ],
            "layout": "IPY_MODEL_0898e9f63ea94b8d81360c537d783c44"
          }
        },
        "06fa748a71294571b9aa3b8f974b2792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ffbbe4eaea242588174b74c65365a1d",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc2265002c84abaa417b82998bc2126",
            "value": "0.024 MB of 0.024 MB uploaded\r"
          }
        },
        "e04a6c17fcb5465783bd6682ad11fd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c8cae9b2f3d465fae969f61c297d058",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2df89465d5e45afbcda87817095d560",
            "value": 1
          }
        },
        "0898e9f63ea94b8d81360c537d783c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ffbbe4eaea242588174b74c65365a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc2265002c84abaa417b82998bc2126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c8cae9b2f3d465fae969f61c297d058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2df89465d5e45afbcda87817095d560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish2021iitd/Deep-Learning/blob/main/DLassignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wandB – Install the W&B library\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "#essentials libararies\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pylab as pl\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J0dLhYQzQF_",
        "outputId": "198a6304-a5fb-43d8-d7ef-5fc089e0e2e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.43.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c9e279-29fb-42cc-a203-d2166f66b7c6",
        "id": "3ha57QLI9iDY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login(key='e3c892d4f8c9cd9b9043d31938ad090f0a32cec1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6df663f1-4945-48b5-f7bf-cb1b2e96b049",
        "id": "Ly-Ny0f09iDY"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240324_065049-23wf8urs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ma23m010/DLassignment1/runs/23wf8urs' target=\"_blank\">usual-violet-3108</a></strong> to <a href='https://wandb.ai/ma23m010/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ma23m010/DLassignment1' target=\"_blank\">https://wandb.ai/ma23m010/DLassignment1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ma23m010/DLassignment1/runs/23wf8urs' target=\"_blank\">https://wandb.ai/ma23m010/DLassignment1/runs/23wf8urs</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Q1\n",
        "wandb.init(project='DLassignment1')\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "#Fashion-MNIST dataset\n",
        "(training_images, training_labels), (testing_images,testing_labels) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "images = [];\n",
        "labels = [];\n",
        "for i in range(54000):\n",
        "  if len(labels) >= 10:\n",
        "    break;\n",
        "  if class_names[training_labels[i]] not in labels:\n",
        "      images.append(training_images[i])\n",
        "      labels.append(class_names[training_labels[i]])\n",
        "wandb.log({\"examples\": [ wandb.Image(img, caption=caption) for img, caption in zip(images,labels)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7dc725-b31b-4252-90b6-b3049384504d",
        "id": "w51t59bh9iDY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Probabilities: [[1.72713679e-01 5.25393396e-05 3.20151821e-04 ... 4.36616035e-04\n",
            "  2.23443018e-06 2.04617986e-04]\n",
            " [4.48853317e-01 2.53774052e-03 3.29381952e-02 ... 4.63643319e-03\n",
            "  2.55640324e-04 3.78639669e-04]\n",
            " [7.21744560e-01 2.31404443e-03 1.44956911e-01 ... 1.72306672e-05\n",
            "  5.62395076e-03 1.70804368e-04]\n",
            " ...\n",
            " [4.79989338e-01 1.18552030e-02 7.27570829e-03 ... 7.50964391e-05\n",
            "  9.99957799e-04 5.03580507e-07]\n",
            " [9.92834041e-01 4.34333665e-03 2.49351452e-05 ... 2.81716898e-06\n",
            "  5.68792533e-04 1.43278319e-04]\n",
            " [1.01112227e-01 6.01226583e-04 3.27763159e-03 ... 4.07127965e-03\n",
            "  2.86459738e-05 1.87150361e-04]]\n"
          ]
        }
      ],
      "source": [
        "#Q2\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        self.input_size = input_size #number of inputs nodes\n",
        "        self.hidden_sizes = hidden_sizes #list of neurons in each hidden layer\n",
        "        self.output_size = output_size #number of output neurons in output layer\n",
        "        self.weights = [] #list of weight matrices for each layer\n",
        "        self.biases = []  #list of bias vectors for each hidden layer and output layer\n",
        "\n",
        "        #innitializing the weights and biases for each layer\n",
        "        sizes = [input_size] + hidden_sizes + [output_size] #using list concatination to make a list of number of nodes in each layer\n",
        "        for i in range(len(sizes) - 1):\n",
        "            self.weights.append(np.random.randn(sizes[i+1], sizes[i]))\n",
        "            self.biases.append(np.random.randn(sizes[i+1]))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "      # Forward pass\n",
        "      activations = [X]\n",
        "      for i in range(len(self.weights)):\n",
        "        z = np.dot(activations[-1], self.weights[i].T) + self.biases[i]\n",
        "        a = self.sigmoid(z) if i < len(self.weights) - 1 else self.softmax(z)\n",
        "        activations.append(a)\n",
        "      return activations\n",
        "\n",
        "    def predict(self, X):\n",
        "        #predict output probabilities\n",
        "        activations = self.forward(X)\n",
        "        return activations[-1]\n",
        "\n",
        "#load fashion-mnist dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "#define neural network\n",
        "input_size = X_train.shape[1]  #28x28 images flattened\n",
        "hidden_sizes = [128, 64]  #size of hidden layers\n",
        "output_size = 10  # 10 classes in fashion-mnist\n",
        "\n",
        "#initialize neural network\n",
        "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
        "\n",
        "#predict probabilities for the test set\n",
        "probabilities = model.predict(X_test)\n",
        "\n",
        "#print the output probabilities\n",
        "print(\"Output Probabilities:\", probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mtUoI5w99iDY"
      },
      "outputs": [],
      "source": [
        "#Q3\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_layers, hidden_sizes, output_size, int_method='random'):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_sizes = hidden_sizes if isinstance(hidden_sizes, list) else [hidden_sizes]\n",
        "        self.output_size = output_size\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        sizes = [input_size] + self.hidden_sizes + [output_size]\n",
        "\n",
        "        for i in range(len(sizes) - 1):\n",
        "            if int_method == \"Xavier\":\n",
        "                self.weights.append(np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(1/sizes[i]))\n",
        "            else:\n",
        "                self.weights.append(np.random.randn(sizes[i], sizes[i+1]))\n",
        "            self.biases.append(np.random.randn(1, sizes[i+1]))\n",
        "\n",
        "        self.adam_v_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def MSE(self,y, y_hat, weight_decay,norm):\n",
        "      loss = np.mean((y-(y_hat.T))**2) + (weight_decay/2)*(norm)\n",
        "      return loss\n",
        "\n",
        "    def Cross_entropy(self, y, y_hat,weight_decay,norm):\n",
        "      #y_hat = np.clip(y_hat.reshape(-1, self.output_size), epsilon, 1 - epsilon)  # clip values to prevent log(0)\n",
        "      loss = -np.mean(y * np.log(y_hat.T)) + (weight_decay/2)*norm\n",
        "      return loss\n",
        "\n",
        "    def frobenius_norm(self,matrix):\n",
        "      return np.linalg.norm(matrix, ord='fro')\n",
        "\n",
        "\n",
        "    def evaluate(self, x, y,act_fun,weight_decay,loss_fun):\n",
        "        predictions = self.forward(x,act_fun)[-1]\n",
        "        predictions =np.array(predictions)\n",
        "        norm = 0\n",
        "        for i in range(len(self.weights)):\n",
        "          norm += self.frobenius_norm(self.weights[i])**2\n",
        "        if loss_fun == 'MSE':\n",
        "          loss = self.MSE(y.reshape(10, -1),predictions,weight_decay,norm)\n",
        "        else:\n",
        "          loss = self.Cross_entropy(y.reshape(10, -1),predictions,weight_decay,norm)\n",
        "        accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y, axis=1))\n",
        "        return loss, accuracy\n",
        "\n",
        "    def activation_fun(self, x, act_fun):\n",
        "        if act_fun == 'sigmoid':\n",
        "            return self.sigmoid(x)\n",
        "        elif act_fun == 'tanh':\n",
        "            return self.tanh(x)\n",
        "        elif act_fun == 'relu':\n",
        "            return self.relu(x)\n",
        "\n",
        "    def der_activation(self, x, act_fun):\n",
        "        if act_fun == 'sigmoid':\n",
        "            return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "        elif act_fun == 'tanh':\n",
        "            return 1. - np.tanh(x) ** 2\n",
        "        elif act_fun == 'relu':\n",
        "            return np.where(x <= 0, 0, 1)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X, act_fun):\n",
        "        activations = [X]\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "            if i < len(self.weights) - 1:\n",
        "                a = self.activation_fun(z, act_fun)\n",
        "            else:\n",
        "                a = self.softmax(z)\n",
        "            activations.append(a)\n",
        "        return activations\n",
        "\n",
        "    def backward(self, X, y, act_fun):\n",
        "        activations = self.forward(X, act_fun)\n",
        "        delta = activations[-1] - y\n",
        "        deltas = [delta]\n",
        "        for i in range(len(self.weights) - 1, 0, -1):\n",
        "            delta = np.dot(deltas[-1], self.weights[i].T) * self.der_activation(activations[i], act_fun)\n",
        "            deltas.append(delta)\n",
        "        deltas.reverse()\n",
        "        return deltas\n",
        "\n",
        "    def update(self, X, y, act_fun,optimizer, learning_rate, weight_decay,beta1 = 0.9,beta2=0.999,epsilon=1e-8):\n",
        "        activations = self.forward(X, act_fun)\n",
        "        deltas = self.backward(X, y, act_fun)\n",
        "\n",
        "        if optimizer == 'sgd':\n",
        "            for i in range(len(self.weights)):\n",
        "                self.weights[i] -= learning_rate * ((np.dot(activations[i].T, deltas[i]) + weight_decay * self.weights[i]))\n",
        "                self.biases[i] -= learning_rate * np.mean(deltas[i], axis=0)\n",
        "\n",
        "\n",
        "        elif optimizer == 'momentum':\n",
        "            #initialize velocities\n",
        "            if not hasattr(self, 'velocities'):\n",
        "                self.velocities = [np.zeros_like(w) for w in self.weights]\n",
        "            beta1 = 0.9  # momentum parameter\n",
        "            for i in range(len(self.weights)):\n",
        "                self.velocities[i] = beta1 * self.velocities[i] + learning_rate * ((np.dot(activations[i].T, deltas[i]) + weight_decay * self.weights[i]))\n",
        "                self.weights[i] -= self.velocities[i]\n",
        "                self.biases[i] -= learning_rate * np.mean(deltas[i], axis=0)\n",
        "\n",
        "        elif optimizer == 'nesterov':\n",
        "            #initialize velocities\n",
        "            if not hasattr(self, 'velocities'):\n",
        "                self.velocities = [np.zeros_like(w) for w in self.weights]\n",
        "            beta1 = 0.9  # momentum parameter\n",
        "            for i in range(len(self.weights)):\n",
        "                lookahead_weights = self.weights[i] - beta1 * self.velocities[i]\n",
        "                lookahead_biases = self.biases[i] - beta1 * np.mean(self.velocities[i], axis=0)\n",
        "                self.velocities[i] = beta1 * self.velocities[i] + learning_rate * ((np.dot(activations[i].T, deltas[i]) + weight_decay * lookahead_weights))\n",
        "                self.weights[i] -= self.velocities[i]\n",
        "                self.biases[i] -= learning_rate * np.mean(deltas[i], axis=0)\n",
        "\n",
        "\n",
        "        elif optimizer == 'rmsprop':\n",
        "          #initialize rmsprop parameters\n",
        "          if not hasattr(self, 'rmsprop_cache_w'):\n",
        "            self.rmsprop_cache_w = [np.zeros_like(w) for w in self.weights]\n",
        "          if not hasattr(self, 'rmsprop_cache_b'):\n",
        "            self.rmsprop_cache_b = [np.zeros_like(b) for b in self.biases]\n",
        "          for i in range(len(self.weights)):\n",
        "            self.rmsprop_cache_w[i] = beta1 * self.rmsprop_cache_w[i] + (1 - beta1) * (np.dot(activations[i].T, deltas[i])**2 )\n",
        "            self.rmsprop_cache_b[i] = beta1 * self.rmsprop_cache_b[i] + (1 - beta1) * np.mean(deltas[i], axis=0)**2\n",
        "            #check for very small or zero values in rmsprop_cache_w[i]\n",
        "            self.rmsprop_cache_w[i][np.abs(self.rmsprop_cache_w[i]) < epsilon] = epsilon\n",
        "            self.weights[i] -= (learning_rate/ (np.sqrt(self.rmsprop_cache_w[i]) + epsilon))*np.dot(activations[i].T, deltas[i]) + learning_rate * weight_decay * self.weights[i]\n",
        "            self.biases[i] -= learning_rate * np.mean(deltas[i], axis=0)  / (np.sqrt(self.rmsprop_cache_b[i]) + epsilon)\n",
        "\n",
        "        elif optimizer == 'adam':\n",
        "          #initialize adam parameters\n",
        "          if not hasattr(self, 'adam_m_w'):\n",
        "            self.adam_m_w = [np.zeros_like(w) for w in self.weights]\n",
        "          if not hasattr(self, 'adam_m_b'):\n",
        "            self.adam_m_b = [np.zeros_like(b) for b in self.biases]\n",
        "          if not hasattr(self, 'adam_v_w'):\n",
        "            self.adam_v_w = [np.zeros_like(w) for w in self.weights]\n",
        "          if not hasattr(self, 'adam_m_b'):\n",
        "            self.adam_v_b = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "          for i in range(len(self.weights)):\n",
        "            self.adam_m_w[i] = beta1 * self.adam_m_w[i] + (1 - beta1) * np.dot(activations[i].T, deltas[i])\n",
        "            self.adam_m_b[i] = beta1 * self.adam_m_b[i] + (1 - beta1) * np.mean(deltas[i], axis=0)\n",
        "            self.adam_v_w[i] = beta2 * self.adam_v_w[i] + (1 - beta2) * (np.dot(activations[i].T, deltas[i]))**2\n",
        "            self.adam_v_b[i] = beta2 * self.adam_v_b[i] + (1 - beta2) * np.mean(deltas[i], axis=0)**2\n",
        "            m_w_hat = self.adam_m_w[i] / (1 - beta1**(i+1))\n",
        "            m_b_hat = self.adam_m_b[i] / (1 - beta1**(i+1))\n",
        "            v_w_hat = self.adam_v_w[i] / (1 - beta2**(i+1))\n",
        "            v_b_hat = self.adam_v_b[i] / (1 - beta2**(i+1))\n",
        "            self.weights[i] -= learning_rate * m_w_hat / (np.sqrt(v_w_hat) + epsilon) + learning_rate * weight_decay * self.weights[i]\n",
        "            self.biases[i] -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n",
        "\n",
        "        elif optimizer == 'nadam':\n",
        "\n",
        "          #initialize adam parameters\n",
        "          if not hasattr(self, 'adam_m_w'):\n",
        "            self.adam_m_w = [np.zeros_like(w) for w in self.weights]\n",
        "          if not hasattr(self, 'adam_m_b'):\n",
        "            self.adam_m_b = [np.zeros_like(b) for b in self.biases]\n",
        "          if not hasattr(self, 'adam_v_w'):\n",
        "            self.adam_v_w = [np.zeros_like(w) for w in self.weights]\n",
        "          if not hasattr(self, 'adam_m_b'):\n",
        "            self.adam_v_b = [np.zeros_like(b) for b in self.biases]\n",
        "          for i in range(len(self.weights)):\n",
        "            self.adam_m_w[i] = beta1 * self.adam_m_w[i] + (1 - beta1) * np.dot(activations[i].T, deltas[i])\n",
        "            self.adam_m_b[i] = beta1 * self.adam_m_b[i] + (1 - beta1) * np.mean(deltas[i], axis=0)\n",
        "            self.adam_v_w[i] = beta2 * self.adam_v_w[i] + (1 - beta2) * (np.dot(activations[i].T, deltas[i]))**2\n",
        "            self.adam_v_b[i] = beta2 * self.adam_v_b[i] + (1 - beta2) * np.mean(deltas[i], axis=0)**2\n",
        "            m_w_hat = self.adam_m_w[i] / (1 - beta1**(i+1))\n",
        "            m_b_hat = self.adam_m_b[i] / (1 - beta1**(i+1))\n",
        "            v_w_hat = self.adam_v_w[i] / (1 - beta2**(i+1))\n",
        "            v_b_hat = self.adam_v_b[i] / (1 - beta2**(i+1))\n",
        "            m_w_bar = beta1*m_w_hat + (1 - beta1)*np.dot(activations[i].T, deltas[i])\n",
        "            m_b_bar = beta1*m_b_hat + (1 - beta1)*np.mean(deltas[i], axis=0)\n",
        "            self.weights[i] -= learning_rate * m_w_bar / (np.sqrt(v_w_hat) + epsilon) + learning_rate * weight_decay * self.weights[i]\n",
        "            self.biases[i] -= learning_rate * m_b_bar / (np.sqrt(v_b_hat) + epsilon)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, X_train, y_train, X_test, y_test_one_hot,act_fun,optimizer,loss_fun, epochs, batch_size, learning_rate, weight_decay):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                X_batch = X_train[i:i+batch_size]\n",
        "                y_batch = y_train[i:i+batch_size]\n",
        "                self.update(X_batch, y_batch, act_fun,optimizer, learning_rate, weight_decay,beta1 = 0.9)\n",
        "\n",
        "\n",
        "            train_loss, train_accuracy = self.evaluate(X_train, y_train,act_fun, weight_decay,loss_fun)\n",
        "            wandb.log({\"train_accuracy\": train_accuracy*100})\n",
        "            wandb.log({\"train_loss\": train_loss})\n",
        "            val_loss, val_accuracy = self.evaluate(X_test, y_test_one_hot,act_fun, weight_decay,loss_fun)\n",
        "            wandb.log({\"val_accuracy\": val_accuracy*100})\n",
        "            wandb.log({\"val_loss\": val_loss})\n",
        "\n",
        "        #return train_loss,train_accuracy\n",
        "\n",
        "    def test(self, X_test, act_fun):\n",
        "        return self.forward(X_test, act_fun)[-1]\n",
        "\n",
        "'''\n",
        "def compute_accuracy(predictions, true_labels):\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "    true_labels = np.argmax(true_labels, axis=1)\n",
        "    accuracy = np.mean(predicted_labels == true_labels)\n",
        "    return accuracy\n",
        "'''\n",
        "\n",
        "#fashion-mnist dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#preprocessing the data\n",
        "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
        "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
        "\n",
        "#convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_one_hot = np.eye(num_classes)[y_train]\n",
        "y_test_one_hot = np.eye(num_classes)[y_test]\n",
        "\n",
        "#define neural network\n",
        "input_size = X_train.shape[1]\n",
        "hidden_layers = 3\n",
        "hidden_sizes = [128,64,32]\n",
        "output_size = num_classes\n",
        "\n",
        "#initialize neural network\n",
        "#model = NeuralNetwork(input_size, hidden_layers, hidden_sizes, output_size, int_method='random')\n",
        "\n",
        "#train the model\n",
        "act_fun = 'tanh'  #change activation function here\n",
        "epochs = 2\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0005  #change weight decay here\n",
        "batch_size = 16  #choose batch sizes here\n",
        "optimizer = 'nadam'\n",
        "\n",
        "#train_loss,train_accuracy=model.train(X_train, y_train_one_hot, act_fun,optimizer, epochs, batch_size, learning_rate, weight_decay)\n",
        "#print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "#test the model\n",
        "#predictions = model.test(X_test, act_fun)\n",
        "#accuracy = NeuralNetwork.evaluate(X_test,predictions, y_test_one_hot)\n",
        "#print(\"Accuracy on test set with batch size :\", accuracy * 100, \"%\")\n",
        "\n",
        "#evaluate on test data\n",
        "#test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot,act_fun,weight_decay)\n",
        "#print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "#References:\n",
        "#1.https://cs229.stanford.edu/main_notes.pdf\n",
        "#2.http://www.cse.iitm.ac.in/~miteshk/CS6910.html\n",
        "#3.https://visualstudiomagazine.com/Articles/2017/06/01/Back-Propagation.aspx?Page=2\n",
        "#4.https://medium.com/@ipylypenko/exploring-neural-networks-with-fashion-mnist-b0a8214b7b7b\n",
        "#5.https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3\n",
        "#7.https://www.youtube.com/watch?v=LQvRhQwDOm0\n",
        "#8.https://towardsdatascience.com/implementing-different-activation-functions-and-weight-initialization-methods-using-python-c78643b9f20f\n",
        "#9.https://medium.com/konvergen/modifying-adam-to-use-nesterov-accelerated-gradients-nesterov-accelerated-adaptive-moment-67154177e1fd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmLr5BoO9iDZ"
      },
      "outputs": [],
      "source": [
        "#Q4,5,6\n",
        "def main():\n",
        "    with wandb.init() as run:\n",
        "        config = wandb.config\n",
        "\n",
        "\n",
        "        hidden_sizes = [config.hidden_sizes] if isinstance(config.hidden_sizes, int) else config.hidden_sizes\n",
        "\n",
        "        model = NeuralNetwork(input_size, config.hidden_layers, config.hidden_sizes, output_size, config.int_method)\n",
        "\n",
        "\n",
        "        model.train(X_train, y_train_one_hot, X_test, y_test_one_hot,config.activation,config.optimizer,config.loss_fun, config.epochs, config.batch_size, config.learning_rate, config.weight_decay)\n",
        "\n",
        "\n",
        "        model.evaluate(X_test, y_test_one_hot,config.activation,config.weight_decay,config.loss_fun)\n",
        "\n",
        "\n",
        "\n",
        "#define the sweep configuration\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'name': 'sweep_cross_entropy',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {'values': [5, 10]},\n",
        "        'hidden_layers': {'values':[3, 4, 5]},\n",
        "        'hidden_sizes': {'values': [32, 64, 128]},\n",
        "        'activation': {'values': ['sigmoid', 'relu', 'tanh']},\n",
        "        'loss_fun': {'values': ['cross_entropy']},\n",
        "        'weight_decay': {'values': [0,0.0005,0.5]},\n",
        "        'learning_rate': {'values': [0.0001, 0.00001]},\n",
        "        'optimizer': {'values': ['sgd','momentum', 'nesterov', 'rmsprop', 'adam', 'nadam']},\n",
        "        'batch_size': {'values': [16, 32, 64]},\n",
        "        'int_method':{'values':['radnom','xavier']}\n",
        "    }\n",
        "}\n",
        "\n",
        "#the sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='DLassignment1')\n",
        "\n",
        "#run the sweep agent\n",
        "wandb.agent(sweep_id, function=main,count=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767,
          "referenced_widgets": [
            "c7df4730d95641b3aa612793753d11c6",
            "06fa748a71294571b9aa3b8f974b2792",
            "e04a6c17fcb5465783bd6682ad11fd7d",
            "0898e9f63ea94b8d81360c537d783c44",
            "2ffbbe4eaea242588174b74c65365a1d",
            "7fc2265002c84abaa417b82998bc2126",
            "6c8cae9b2f3d465fae969f61c297d058",
            "d2df89465d5e45afbcda87817095d560"
          ]
        },
        "id": "6fXsjydI9iDa",
        "outputId": "49bcfec9-616d-4f15-f79d-95db8408e8b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240324_062759-iqzfsvck</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ma23m010/DLassignment1/runs/iqzfsvck' target=\"_blank\">logical-glade-3107</a></strong> to <a href='https://wandb.ai/ma23m010/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ma23m010/DLassignment1' target=\"_blank\">https://wandb.ai/ma23m010/DLassignment1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ma23m010/DLassignment1/runs/iqzfsvck' target=\"_blank\">https://wandb.ai/ma23m010/DLassignment1/runs/iqzfsvck</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.95%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7df4730d95641b3aa612793753d11c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>85.38167</td></tr><tr><td>train_loss</td><td>637.18387</td></tr><tr><td>val_accuracy</td><td>83.95</td></tr><tr><td>val_loss</td><td>637.17833</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">logical-glade-3107</strong> at: <a href='https://wandb.ai/ma23m010/DLassignment1/runs/iqzfsvck' target=\"_blank\">https://wandb.ai/ma23m010/DLassignment1/runs/iqzfsvck</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240324_062759-iqzfsvck/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Q7 confusion matrix for best hyperparameters for validation accuracy of 83.91%\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import wandb\n",
        "\n",
        "# Load fashion-mnist dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
        "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_one_hot = np.eye(num_classes)[y_train]\n",
        "y_test_one_hot = np.eye(num_classes)[y_test]\n",
        "\n",
        "# Best hyperparameters\n",
        "best_epochs = 10\n",
        "best_hidden_layers = 4\n",
        "best_hidden_size = 128\n",
        "best_weight_decay = 0.5\n",
        "best_learning_rate = 0.0001\n",
        "best_batch_size = 16\n",
        "best_act_fun = 'tanh'\n",
        "best_loss_fun = 'cross_entropy'\n",
        "best_weight_init = 'random'\n",
        "best_optimizer = 'rmsprop'\n",
        "\n",
        "# Define and train the model with best hyperparameters\n",
        "model = NeuralNetwork(input_size=X_train.shape[1],\n",
        "                      hidden_layers=best_hidden_layers,\n",
        "                      hidden_sizes=best_hidden_size,\n",
        "                      output_size=num_classes,\n",
        "                      int_method=best_weight_init)\n",
        "\n",
        "# Initialize W&B run\n",
        "wandb.init(project='DLassignment1', config={\n",
        "    'epochs': best_epochs,\n",
        "    'hidden_layers': best_hidden_layers,\n",
        "    'hidden_size': best_hidden_size,\n",
        "    'weight_decay': best_weight_decay,\n",
        "    'learning_rate': best_learning_rate,\n",
        "    'batch_size': best_batch_size,\n",
        "    'activation_function': best_act_fun,\n",
        "    'loss_function': best_loss_fun,\n",
        "    'weight_initialization': best_weight_init,\n",
        "    'optimizer': best_optimizer\n",
        "})\n",
        "\n",
        "# Train the model\n",
        "model.train(X_train, y_train_one_hot, X_test, y_test_one_hot,\n",
        "            best_act_fun, best_optimizer, best_loss_fun,\n",
        "            best_epochs, best_batch_size, best_learning_rate,\n",
        "            best_weight_decay)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot, best_act_fun, best_weight_decay, best_loss_fun)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# Generate predictions on the test set\n",
        "predictions = model.test(X_test, best_act_fun)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "img  = pl.matshow(conf_matrix)\n",
        "pl.title('Confusion matrix')\n",
        "pl.colorbar()\n",
        "pl.show()\n",
        "\n",
        "wandb.log({\"confusion matrix\": [ wandb.Image(img, caption='confusion matrix') ]})\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz66yDLW9iDa"
      },
      "outputs": [],
      "source": [
        "#Q8 In all the models above we used cross entropy loss. Now to compare the cross entropy loss with the squared error loss.\n",
        "def main():\n",
        "    with wandb.init() as run:\n",
        "        config = wandb.config\n",
        "\n",
        "\n",
        "        hidden_sizes = [config.hidden_sizes] if isinstance(config.hidden_sizes, int) else config.hidden_sizes\n",
        "\n",
        "        model = NeuralNetwork(input_size, config.hidden_layers, config.hidden_sizes, output_size, config.int_method)\n",
        "\n",
        "\n",
        "        model.train(X_train, y_train_one_hot, X_test, y_test_one_hot,config.activation,config.optimizer,config.loss_fun, config.epochs, config.batch_size, config.learning_rate, config.weight_decay)\n",
        "\n",
        "\n",
        "        model.evaluate(X_test, y_test_one_hot,config.activation,config.weight_decay,config.loss_fun)\n",
        "\n",
        "\n",
        "\n",
        "#define the sweep configuration\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'name': 'sweep_MSE',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {'values': [5, 10]},\n",
        "        'hidden_layers': {'values':[3, 4, 5]},\n",
        "        'hidden_sizes': {'values': [32, 64, 128]},\n",
        "        'activation': {'values': ['sigmoid', 'relu', 'tanh']},\n",
        "        'loss_fun': {'values': ['MSE']},\n",
        "        'weight_decay': {'values': [0,0.0005,0.5]},\n",
        "        'learning_rate': {'values': [0.0001, 0.00001]},\n",
        "        'optimizer': {'values': ['sgd','momentum', 'nesterov', 'rmsprop', 'adam', 'nadam']},\n",
        "        'batch_size': {'values': [16, 32, 64]},\n",
        "        'int_method':{'values':['radnom','xavier']}\n",
        "    }\n",
        "}\n",
        "\n",
        "#the sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='DLassignment1')\n",
        "\n",
        "# Run the sweep agent\n",
        "wandb.agent(sweep_id, function=main,count=150)"
      ]
    }
  ]
}